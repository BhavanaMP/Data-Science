{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81394586",
   "metadata": {},
   "source": [
    "    While the Pillow library is primarily used for image processing, it can be a valuable tool for machine learning practitioners working on image-based projects.  PIL is the Python Imaging Library which provides the python interpreter with image editing capabilities. The Image module provides a class with the same name which is used to represent a PIL image. The module also provides a number of factory functions, including functions to load images from files, and to create new images.\n",
    "    \n",
    "    Image.show() Displays this image. This method is mainly intended for debugging purposes. \n",
    "\n",
    "    On Unix platforms, this method saves the image to a temporary PPM file(Portable Pixmap Format), and calls the xv utility. On Linux mac, it saves as PI(photo image) file. On Windows, it saves the image to a temporary BMP(bitmap - grid of pixels of different pixel intensities, high quality image) file, and uses the standard BMP display utility to show it (usually Paint).\n",
    "    \n",
    "    Like PIL, we also have OpenCV which is a huge open-source library for computer vision, machine learning, and image processing\n",
    "    \n",
    "    Here are some more Pillow library tutorials specifically tailored for ML practitioners:\n",
    "\n",
    "#### Image Data Loading for ML:\n",
    "\n",
    "    Learn how to use Pillow to load images from a directory, preprocess them (e.g., resize, crop, normalize), and convert them into numpy arrays or tensors suitable for feeding into ML models.\n",
    "\n",
    "#### Data Augmentation:\n",
    "\n",
    "    Data augmentation is crucial for increasing the diversity of your training dataset. Learn how to use Pillow to apply various image transformations such as rotations, flips, brightness adjustments, and more.\n",
    "\n",
    "#### Creating Image Thumbnails:\n",
    "\n",
    "    In some cases, you may need to create thumbnail versions of images to use as previews or in data visualization. Learn how to use Pillow to generate image thumbnails.\n",
    "\n",
    "#### Image Concatenation and Stitching:\n",
    "\n",
    "    If you're working with images that are larger than your model's input size, learn how to use Pillow to split them into smaller patches, and vice versa, stitch smaller images into a larger one.\n",
    "\n",
    "#### Image Filtering and Enhancements:\n",
    "\n",
    "    Explore techniques like blurring, sharpening, edge detection, and contrast adjustments using Pillow to preprocess images before feeding them into ML models.\n",
    "\n",
    "#### Handling Image Channels and Color Spaces:\n",
    "\n",
    "    Learn how to extract and manipulate image channels (e.g., RGB, HSV) using Pillow, which can be useful for certain ML tasks.\n",
    "\n",
    "#### Overlaying Annotations on Images:\n",
    "\n",
    "    If you're working on object detection or segmentation tasks, learn how to use Pillow to overlay bounding boxes, polygons, or masks on images to visualize ground truth or model predictions.\n",
    "\n",
    "#### Converting Images to Grayscale and Binary:\n",
    "\n",
    "    Explore methods to convert color images to grayscale or binary images, which can be useful for certain ML algorithms or tasks.\n",
    "#### Working with Image Metadata:\n",
    "\n",
    "    Learn how to extract and modify metadata (Exif data) from images using Pillow.\n",
    "\n",
    "#### Creating Image Collages:\n",
    "\n",
    "    Use Pillow to create collages by arranging multiple images together, which can be useful for data visualization or presenting results.\n",
    "\n",
    "#### Handling Animated GIFs:\n",
    "\n",
    "    If you're dealing with animated GIFs, learn how to extract frames, modify them, and create new GIFs using Pillow.\n",
    "\n",
    "    Remember that while Pillow is an excellent library for basic image processing tasks, for more advanced deep learning projects, you may want to use specialized libraries like TensorFlow or PyTorch, which offer GPU acceleration and deep learning-specific functionalities. Pillow, however, can be a valuable addition to your ML toolbox, especially for data preparation and visualization when working with image data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7fcee",
   "metadata": {},
   "source": [
    "    The Python Imaging Library (PIL) has been discontinued and replaced with the Pillow library, which is a more actively maintained fork. Pillow provides easy-to-use functions to work with images in Python. \n",
    "    Here's a fast and short tutorial on how to use the Pillow library:\n",
    "\n",
    "##### Installation:\n",
    "    First, make sure you have Pillow installed. You can install it using pip:\n",
    "    \n",
    "                    pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the library:\n",
    "#Import the PIL module from Pillow:\n",
    "from PIL import Image\n",
    "\n",
    "#Opening an image:\n",
    "#Load an image using the open() function:\n",
    "\n",
    "image = Image.open(\"path/to/your/image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2029e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the image:\n",
    "#To display the image, you can use the show() method:\n",
    "\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3bcc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting image information:\n",
    "#You can get basic information about the image using the following methods:\n",
    "\n",
    "width, height = image.size\n",
    "image_format = image.format\n",
    "image_mode = image.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178afabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing an image:\n",
    "#To resize an image, use the resize() method:\n",
    "\n",
    "new_size = (width, height)  # Tuple of the new size (width, height)\n",
    "resized_image = image.resize(new_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the image:\n",
    "#To save the modified image, use the save() method:\n",
    "\n",
    "resized_image.save(\"path/to/save/resized_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e906644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image processing:\n",
    "#Pillow provides various image processing operations like converting to grayscale, rotating, cropping, etc. \n",
    "#Here's an example of converting an image to grayscale:\n",
    "\n",
    "grayscale_image = image.convert(\"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc38c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the image:\n",
    "#Always close the image after you are done working with it:\n",
    "\n",
    "image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120b5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert files to JPEG\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "\n",
    "for infile in sys.argv[1:]:\n",
    "    f, e = os.path.splitext(infile)\n",
    "    outfile = f + \".jpg\"\n",
    "    if infile != outfile:\n",
    "        try:\n",
    "            with Image.open(infile) as im:\n",
    "                im.save(outfile)\n",
    "        except OSError:\n",
    "            print(\"cannot convert\", infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create JPEG thumbnails\n",
    "import os, sys\n",
    "from PIL import Image\n",
    "\n",
    "size = (128, 128)\n",
    "\n",
    "for infile in sys.argv[1:]:\n",
    "    outfile = os.path.splitext(infile)[0] + \".thumbnail\"\n",
    "    if infile != outfile:\n",
    "        try:\n",
    "            with Image.open(infile) as im:\n",
    "                im.thumbnail(size)\n",
    "                im.save(outfile, \"JPEG\")\n",
    "        except OSError:\n",
    "            print(\"cannot create thumbnail for\", infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data Loading for ML:\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load images from a directory and convert them into numpy arrays\n",
    "def load_images(directory_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        image_path = os.path.join(directory_path, filename)\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((64, 64))  # Resize the image to a fixed size\n",
    "        image_np = np.array(image)\n",
    "        images.append(image_np)\n",
    "    return np.array(images)\n",
    "\n",
    "# Example usage:\n",
    "data_directory = \"path/to/your/image/directory\"\n",
    "image_data = load_images(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46861997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation:\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "\n",
    "# Data augmentation by rotating, flipping, and adjusting brightness\n",
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "\n",
    "    # Original image\n",
    "    augmented_images.append(image)\n",
    "\n",
    "    # Rotated images (90, 180, 270 degrees)\n",
    "    for angle in [90, 180, 270]:\n",
    "        rotated_image = image.rotate(angle)\n",
    "        augmented_images.append(rotated_image)\n",
    "\n",
    "    # Flipped images (horizontal and vertical)\n",
    "    flipped_image_h = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    flipped_image_v = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    augmented_images.extend([flipped_image_h, flipped_image_v])\n",
    "\n",
    "    # Brightness adjustments\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    augmented_images.extend([enhancer.enhance(factor) for factor in [0.8, 1.2]])\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "image = Image.open(image_path)\n",
    "augmented_images = augment_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Image Thumbnails:\n",
    "from PIL import Image\n",
    "\n",
    "# Create a thumbnail of the image\n",
    "def create_thumbnail(image_path, thumbnail_size=(100, 100)):\n",
    "    image = Image.open(image_path)\n",
    "    image.thumbnail(thumbnail_size)\n",
    "    return image\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "thumbnail_image = create_thumbnail(image_path)\n",
    "thumbnail_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996f8652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Concatenation and Stitching:\n",
    "from PIL import Image\n",
    "\n",
    "# Split an image into smaller patches\n",
    "def split_image(image, patch_size=(100, 100)):\n",
    "    width, height = image.size\n",
    "    patches = []\n",
    "    for x in range(0, width, patch_size[0]):\n",
    "        for y in range(0, height, patch_size[1]):\n",
    "            box = (x, y, x + patch_size[0], y + patch_size[1])\n",
    "            patch = image.crop(box)\n",
    "            patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "# Stitch smaller images into a larger one\n",
    "def stitch_images(patches, original_size):\n",
    "    stitched_image = Image.new(\"RGB\", original_size)\n",
    "    x_offset = 0\n",
    "    y_offset = 0\n",
    "    for patch in patches:\n",
    "        stitched_image.paste(patch, (x_offset, y_offset))\n",
    "        x_offset += patch.width\n",
    "        if x_offset >= original_size[0]:\n",
    "            x_offset = 0\n",
    "            y_offset += patch.height\n",
    "    return stitched_image\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "original_image = Image.open(image_path)\n",
    "image_patches = split_image(original_image, patch_size=(100, 100))\n",
    "stitched_image = stitch_images(image_patches, original_image.size)\n",
    "stitched_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef58158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Filtering and Enhancements:\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "\n",
    "# Apply Gaussian blur and edge enhancement\n",
    "def apply_filters(image):\n",
    "    blurred_image = image.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "    enhanced_image = ImageOps.autocontrast(blurred_image)\n",
    "    return enhanced_image\n",
    "\n",
    "# Example usage:\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "image = Image.open(image_path)\n",
    "filtered_image = apply_filters(image)\n",
    "filtered_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae0ed2",
   "metadata": {},
   "source": [
    "    In image processing and computer vision tasks, annotations are used to mark objects or regions of interest in an image. These annotations can be bounding boxes, polygons, or masks that provide additional information about the objects present in the image. The Python Imaging Library (PIL) doesn't have built-in support for drawing annotations directly on images, but we can create an annotated layout using Pillow to visualize the annotations. Below is an example of how to create an annotation layout using Pillow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfb423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image annotation, bounding box\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Function to draw annotations on the image and create an annotated layout\n",
    "def create_annotation_layout(image_path, annotations):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Create a drawing context\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Define a function to draw annotations based on their type\n",
    "    def draw_annotation(annotation):\n",
    "        annotation_type = annotation['type']\n",
    "        if annotation_type == 'box':\n",
    "            x, y, w, h = annotation['bbox']\n",
    "            draw.rectangle([x, y, x + w, y + h], outline='red', width=2)\n",
    "        elif annotation_type == 'polygon':\n",
    "            points = annotation['points']\n",
    "            draw.polygon(points, outline='blue', width=2)\n",
    "        elif annotation_type == 'mask':\n",
    "            mask = Image.new('L', image.size, 0)\n",
    "            draw_mask = ImageDraw.Draw(mask)\n",
    "            draw_mask.polygon(annotation['points'], outline='white', fill='white')\n",
    "            image.putalpha(mask)\n",
    "\n",
    "    # Draw annotations on the image\n",
    "    for annotation in annotations:\n",
    "        draw_annotation(annotation)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Example usage:\n",
    "# Let's assume you have a list of annotations, each containing the type and appropriate data.\n",
    "annotations = [\n",
    "    {\n",
    "        'type': 'box',\n",
    "        'bbox': (100, 50, 200, 150)  # (x, y, width, height)\n",
    "    },\n",
    "    {\n",
    "        'type': 'polygon',\n",
    "        'points': [(300, 100), (400, 200), (350, 300)]  # List of (x, y) points\n",
    "    },\n",
    "    {\n",
    "        'type': 'mask',\n",
    "        'points': [(500, 50), (600, 100), (550, 200)]  # List of (x, y) points\n",
    "    }\n",
    "]\n",
    "\n",
    "# Replace 'path/to/your/image.jpg' with the path to the image you want to annotate.\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "\n",
    "annotated_image = create_annotation_layout(image_path, annotations)\n",
    "annotated_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0338896",
   "metadata": {},
   "source": [
    "    In this example, the create_annotation_layout() function takes the path to an image and a list of annotations as input. The annotations should be provided as dictionaries, where each dictionary contains the type of annotation ('box', 'polygon', or 'mask') and the necessary data to draw the annotation.\n",
    "\n",
    "    Keep in mind that this example focuses on creating an annotated layout for visualization purposes. In a real-world scenario, you might load annotations from an annotation file (e.g., JSON, XML) and map them to the image's coordinates to draw accurate annotations. Also, consider using dedicated annotation tools like Labelbox, VGG Image Annotator (VIA), or COCO Annotator for more complex annotation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa2405",
   "metadata": {},
   "source": [
    "#### Drawing annotations directly on images by detecting objects automatically\n",
    "    Drawing annotations directly on images by detecting objects automatically typically involves using pre-trained object detection models or custom-trained models. While Pillow itself does not have built-in object detection capabilities, we can combine Pillow with other libraries like TensorFlow or PyTorch to achieve this. Here's an example using the popular object detection library, TensorFlow Object Detection API:\n",
    "\n",
    "    In this example, we use the TensorFlow Object Detection API to load a pre-trained object detection model and the corresponding label map. The detect_and_annotate() function performs object detection on the image and draws bounding boxes around the detected objects with their corresponding labels and confidence scores.\n",
    "\n",
    "    Please note that using object detection models often requires significant computational resources and may work best with GPU support. Ensure that you have installed the required dependencies, including TensorFlow and the Object Detection API, to run this example successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec900d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageDraw\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "# Function to load a pre-trained object detection model\n",
    "def load_model(model_path, label_map_path):\n",
    "    detection_model = tf.saved_model.load(model_path)\n",
    "    label_map = label_map_util.load_labelmap(label_map_path)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return detection_model, category_index\n",
    "\n",
    "# Function to perform object detection and draw annotations on the image\n",
    "def detect_and_annotate(image_path, model, category_index, min_score_thresh=0.5):\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    input_tensor = tf.convert_to_tensor(image_np)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    image_with_annotations = image_np.copy()\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_with_annotations,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=detections.get('detection_masks_reframed', None),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=5,\n",
    "        min_score_thresh=min_score_thresh\n",
    "    )\n",
    "\n",
    "    return Image.fromarray(image_with_annotations)\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'path/to/your/model/' and 'path/to/your/label_map.pbtxt' with your pre-trained model and label map file.\n",
    "model_path = 'path/to/your/model/'\n",
    "label_map_path = 'path/to/your/label_map.pbtxt'\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "\n",
    "# Load the model and label map\n",
    "model, category_index = load_model(model_path, label_map_path)\n",
    "\n",
    "# Perform object detection and draw annotations on the image\n",
    "annotated_image = detect_and_annotate(image_path, model, category_index)\n",
    "\n",
    "# Display the annotated image\n",
    "annotated_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
