{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab4ec39",
   "metadata": {},
   "source": [
    "### Adam: (Adaptive moment estimation)\n",
    "    Adam is an optimization algorithm just like gradient descent to optimize the parameters w and b in order to minimize the cost J. \n",
    "    The only difference between Adam and Gradient descent is, for GD, the learning rate is global for all the parameters i,e its wont change through out the entire training process.\n",
    "    Whereas for Adam, the learning rate is different for every parameters w and b instead of global learning rate, and these learning rates are adapatable for each training step.\n",
    "    To be specific, imagine we have a contour graph of elipses (w1 vs w2 with contours ellipses of J(w1, w2)) The ellipses represent the cost for each w1 and w2. The center of the ellipses is where the cost is minimum. So, during the training process, the w1 and w2 are adjusted/updated to reach the minimum cost and this is what done by gradient descent algorithm.\n",
    "    For every update, the gradient descent is moving the cost to move towards the center of the ellipses. \n",
    "    \n",
    "    If the algorithm were to observe that gradient descent is moving in the same direction by taking little little steps(learning rate alpha), then it takes the liberty to make the step bigger by changing the learning rate little bigger. Hence we achieve fast convergence.\n",
    "    \n",
    "    In another case, if the algorithm were to observe that gradient descent is highly jumping by taking larger steps(learning rate alpha), then it takes the liberty to make the step smaller by changing the learning rate to smaller number. \n",
    "    \n",
    "    This way Adam adapts/adjust the learning rate based on gradient descent movement\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731c4b4",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "    Dense layer or fully connected layer is the type of layer where all the inputs from the previous layer is connected as to input to each and every unit of the current layer. This sometimes may lead to higher time consumption for calculations.\n",
    "    \n",
    "    Convolutional layer is the layer where each unit will be connected only some inputs of the previous layer. The network with convolutional layers are called convolutional neural network.\n",
    "    \n",
    "    Imagine, we have ecg image of heart. When we convert the image to pixels(vertical image) and feed to the CNN network, the first unit in the first cnn layer will see some part of ecg pixels, second unit will see another part of the image and so on.\n",
    "    \n",
    "    This needs some architectural choices like, window size that is to be seen by each unit, no of layers in the hidden cnn layers etc.\n",
    "    \n",
    "    Because of this kind of architecuture, CNN is less prone to overfitting, less time consumption, needed less training data compared to dense layers, very useful when dealing with image data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e1397",
   "metadata": {},
   "source": [
    "### Backward propagation Intro:\n",
    "\n",
    "    In Neural network, just like linear regression / logistic regression, the params w and b are updated until the cost J is reduced. In order to update the params(update rule), we use an optimization algorithm like Gradient Descent, Adaptive Moment estimation(ADAM)\n",
    "    \n",
    "    Frameworks like tensorflow (using which we design Neural networks) uses computational graph to calculate output, cost and gradients efficiently and effectively\n",
    "    \n",
    "    We know to update the params, we ought to calculate derivates of cost w.r.to all the network parameters. For neural networks, the frameworks like tensorflow uses backward propagation algorithm with computaional graph to efficiently calculate derivates dJ/dw, dJ/db\n",
    "    \n",
    "    Before talking about backward prop, we know that forward prop is moving from left to right calculation on computational graph to get the output of the network.\n",
    "    \n",
    "    Backward prop is moving from right to left calculation on the computational graph to calculate derivatives\n",
    "    \n",
    "    Backprop uses chain rule to calculate the derivates from right to left"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9101b",
   "metadata": {},
   "source": [
    "### Relation between w, J and dj/dw\n",
    "    If w were to increase by infinitesimally small number ε = 0.001, then J were to increase by k times ε = kε where dJ/dw = k (slope of the line of w vs J graph at particular (w, J))  \n",
    "    \n",
    "    If w goes up by epsilon ε, then J goes up by k*ε where k is the derivate dJ/dw which is the rate of change of J w.r.to w\n",
    "    \n",
    "    This means, if there is a change in w by ε, then it changes the cost J by ktimesε i.e the rate of change in J w.r.to w (dj/dw) is k \n",
    "        \n",
    "     How fast the change in w effects the change in J is k i.e dj/dw = k\n",
    "     \n",
    "     See more on this in the below code cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754d27e",
   "metadata": {},
   "source": [
    "### Chain rule\n",
    "    The chain rule helps us understand how things change when they depend on multiple factors.\n",
    "    \n",
    "    Formula\n",
    "    -------\n",
    "        \n",
    "     The chain rule is a fundamental rule in calculus that allows us to find the derivative of a composite function. It is used when a function is composed of two or more functions combined together.\n",
    "\n",
    "    Suppose we have two functions, u and v, where v depends on u. The composite function is denoted as f(v(u)), which means the output of u becomes the input of v, and the final output is f.\n",
    "\n",
    "    The chain rule states that the derivative of the composite function f(v(u)) with respect to x is the product of two derivatives:\n",
    "                    dy/ dx = dy/du * du/dx when y = f(u), u= g(x)\n",
    "                    \n",
    "                    (d/dx) f(v(u)) = (df/dv) * (dv/du) * (du/dx)\n",
    "            \n",
    "            Where:\n",
    "\n",
    "            (d/dx) represents the derivative with respect to x.\n",
    "            (df/dv) is the derivative of f with respect to v.\n",
    "            (dv/du) is the derivative of v with respect to u.\n",
    "            (du/dx) is the derivative of u with respect to x.\n",
    "\n",
    "    The chain rule allows us to find the rate at which f(v(u)) changes concerning x when it depends on multiple variables.\n",
    "    \n",
    "        For example, let's say we have y = (x^2 + 3)^3, and we want to find (dy/dx) using the chain rule: \n",
    "        \n",
    "        note that y is a function of x, u is a function of x, v is a func of u, f is a function of v\n",
    "\n",
    "                u = x^2 + 3\n",
    "                v = u^3\n",
    "                f = v\n",
    "\n",
    "                (df/dv) = d(v^3)/dv = 3v^2 = 3(x^2 + 3)^2\n",
    "                (dv/du) = d(u^3)/du = 3u^2 = 3(x^2 + 3)^2\n",
    "                (du/dx) = d(x^2 + 3)/dx = 2x\n",
    "\n",
    "                (dy/dx) = (df/dv) * (dv/du) * (du/dx) = 3(x^2 + 3)^2 * 3(x^2 + 3)^2 * 2x = 6x(x^2 + 3)^4\n",
    "                So, the derivative (dy/dx) of y = (x^2 + 3)^3 with respect to x using the chain rule is 6x(x^2 + 3)^4.\n",
    "                \n",
    "                \n",
    "     Eg 2: Consider the following mathematical expression:\n",
    "\n",
    "                        f(x) = (x^2 + 3) * (2x + 1)\n",
    "                        \n",
    "        The expression f(x) consists of two smaller functions multiplied together: (x^2 + 3) and (2x + 1).\n",
    "\n",
    "        To find the derivative of f(x) with respect to x (i.e., how fast f(x) changes concerning x), we use the chain rule.\n",
    "\n",
    "        Step 1: Find the derivatives of the smaller functions:\n",
    "\n",
    "                The derivative of (x^2 + 3) with respect to x is d/dx (x^2 + 3) = 2x.\n",
    "                The derivative of (2x + 1) with respect to x is d/dx (2x + 1) = 2.\n",
    "         Step 2: Apply the chain rule:\n",
    "                The chain rule says that to find the derivative of the entire expression f(x), we need to multiply the derivatives of the smaller functions.\n",
    "\n",
    "                So, f'(x) = (2x) * (2) = 4x.\n",
    "\n",
    "                The derivative f'(x) = 4x tells us how fast the function f(x) changes concerning x at any point. For example, if we plug in x = 2 into f'(x), we get f'(2) = 4 * 2 = 8. This means that when x = 2, the function f(x) is changing at a rate of 8 units per unit change in x.\n",
    "\n",
    "        In summary, the chain rule helps us find the derivative of a composite function (a function composed of smaller functions) by multiplying the derivatives of its smaller parts. It's a fundamental rule in calculus and is used in various real-world applications to understand how quantities change concerning each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3418b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computation_graph.pdf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating sample computation graph using graphviz\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Create a Digraph object\n",
    "graph = Digraph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.node('A', label='Input A')\n",
    "graph.node('B', label='Input B')\n",
    "graph.node('C', label='Intermediate Node C')\n",
    "graph.node('D', label='Output D')\n",
    "\n",
    "# Add edges to connect the nodes\n",
    "graph.edge('A', 'C', label='Operation 1')\n",
    "graph.edge('B', 'C', label='Operation 2')\n",
    "graph.edge('C', 'D', label='Operation 3')\n",
    "\n",
    "# Render the graph to a file (e.g., computation_graph.png)\n",
    "graph.render('computation_graph', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5260b07",
   "metadata": {},
   "source": [
    "### Derivatives using sympy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bb738c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sympy.core.symbol.Symbol'>\n",
      "J w\n"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "\n",
    "#creating symbols for J and w\n",
    "J, w = sympy.symbols(\"J, w\")\n",
    "print(type(J))\n",
    "print(J, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8a5ca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle w^{2}$"
      ],
      "text/plain": [
       "w**2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making the sample cost function => give the output in nifty format\n",
    "J = w**2\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09d756f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2 w$"
      ],
      "text/plain": [
       "2*w"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#specifying the differentiation rule J w.r.to w\n",
    "dj_dw = sympy.diff(J, w)\n",
    "dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70b35e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculation J when w = 3\n",
    "J = 3**2\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eafad403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 6$"
      ],
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculation dj_dw after assigning w as 3\n",
    "dj_dw.subs([(w, 3)]) #derivative at point w as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61426345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle -6$"
      ],
      "text/plain": [
       "-6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dj_dw.subs([(w, -3)]) #derivate at point -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "269b8967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.006001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##increase w by epsilo=0.001 and cal J\n",
    "J = 3.001**2\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5ae6edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 6.002$"
      ],
      "text/plain": [
       "6.00200000000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#increase w by epsilo=0.001 => increase in w by epsilon increases J by k*epsilon where k is the rate of change in J by change in w i.e dj/dw\n",
    "k = dj_dw.subs(w, 3.001)\n",
    "k\n",
    "# J = 9 when w=3.\n",
    "#When w increased by 0.001 i.e w=3 .001, \n",
    "#then J = 9.006001 = 9 + (0.006001) = 9 + (epsilon * 6.001) => J is increased by 6.001epsilon => k = 6.001 => dj/dw = 6.001\n",
    "#as per lecture, #then J = 9.006001 = 9 + (0.001 * 6) = 9 + (epsilon * 6.) => J is increased by 6epsilon => k = 6 => dj/dw = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "452f18b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 9, J_epsilon = 9.006001, dJ_dw ~= k = 6.001000 \n"
     ]
    }
   ],
   "source": [
    "#Manual calculation to prove the above values\n",
    "J = (3)**2\n",
    "J_epsilon = (3 + 0.001)**2\n",
    "k = (J_epsilon - J)/0.001    # difference divided by epsilon\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k:0.6f} \")\n",
    "\n",
    "#the calculation values are differing a bit after the decimals cuz of epsilon not being infinetesimally small.\n",
    "#If we reduce epsilon to infintesimally small, then the output of k will be equal to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ee4b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 9, J_epsilon = 9.0000000006, dJ_dw ~= k = 6.000000496442226 \n"
     ]
    }
   ],
   "source": [
    "J = (3)**2\n",
    "J_epsilon = (3 + 0.0000000001)**2\n",
    "k = (J_epsilon - J)/0.0000000001\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k} \")\n",
    "#The value gets close to exactly 6 as we reduce the size of epsilon. Feel free to try reducing the value further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a5b4344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2 w$"
      ],
      "text/plain": [
       "2*w"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when j = 2w\n",
    "J = 2 * w\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a94cb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2$"
      ],
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ_dw = sympy.diff(J, w)\n",
    "dJ_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31121421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 2$"
      ],
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ_dw.subs([(w, -3)])    # derivative at the point w = -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c16fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 6, J_epsilon = 6.002, dJ_dw ~= k = 1.9999999999997797 \n"
     ]
    }
   ],
   "source": [
    "#Compare this with the arithmetic calculation\n",
    "J = 2 * 3\n",
    "J_epsilon = 2 * (3 + 0.001)\n",
    "k = (J_epsilon - J) / 0.001\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k} \")\n",
    "\n",
    "#For the function J, it is easy to see that any change in w will result in 2 times that amount of change in the output J,\n",
    "#regardless of the starting value of w. Our NumPy and arithmetic results confirm this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e563172e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle w^{3}$"
      ],
      "text/plain": [
       "w**3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = w**3\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24e253a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 3 w^{2}$"
      ],
      "text/plain": [
       "3*w**2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ_dw = sympy.diff(J, w)\n",
    "dJ_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "773e70ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 12$"
      ],
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ_dw.subs([(w, 2)])   # derivative at the point w=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f01175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 8, J_epsilon = 8.012006000999998, dJ_dw ~= k = 12.006000999997823 \n"
     ]
    }
   ],
   "source": [
    "#Compare this with the arithmetic calculation\n",
    "J = (2)**3\n",
    "J_epsilon = (2 + 0.001) ** 3\n",
    "k = (J_epsilon - J) / 0.001\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07024d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{1}{w}$"
      ],
      "text/plain": [
       "1/w"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = 1/w\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "696bb603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{1}{w^{2}}$"
      ],
      "text/plain": [
       "-1/w**2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ_dw = sympy.diff(J, w)\n",
    "dJ_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a8453b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{1}{4}$"
      ],
      "text/plain": [
       "-1/4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ_dw.subs([(w, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86fed262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 0.5, J_epsilon = 0.49975012493753124, dJ_dw ~= k = -0.2498750624687629 \n"
     ]
    }
   ],
   "source": [
    "#Compare this with the arithmetic calculation\n",
    "\n",
    "J = 1/2\n",
    "J_epsilon = 1/(2 + 0.001)\n",
    "k = (J_epsilon - J) / 0.001\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5d47fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{1}{w^{2}}$"
      ],
      "text/plain": [
       "w**(-2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J = 1 / w**2\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d923d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{2}{w^{3}}$"
      ],
      "text/plain": [
       "-2/w**3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dj_dw = sympy.diff(J, w)\n",
    "dj_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5340746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{1}{16}$"
      ],
      "text/plain": [
       "-1/16"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dJ_dw.subs([(w, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb1499df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 0.0625, J_epsilon = 0.06246876171484496, dJ_dw ~= k = -0.031238285155041345 \n"
     ]
    }
   ],
   "source": [
    "#Compare this with the arithmetic calculation\n",
    "\n",
    "J = 1/4**2\n",
    "J_epsilon = 1 / (4 + 0.001) ** 2\n",
    "k = (J_epsilon - J) / 0.001\n",
    "print(f\"J = {J}, J_epsilon = {J_epsilon}, dJ_dw ~= k = {k} \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
