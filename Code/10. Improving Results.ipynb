{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60712b2c",
   "metadata": {},
   "source": [
    "#### Improving results:\n",
    "\n",
    "    The three strategies to improve the performance of ML algorithm is:\n",
    "\n",
    "        1. Algorithm Tuning\n",
    "        2. Ensembles\n",
    "        3. Extreme Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ef1559",
   "metadata": {},
   "source": [
    "### 1. Algorithm Tuning\n",
    "    Machine learning algorithms are parameterized and modification of those parameters can influence the outcome of the learning process. Think of each algorithm parameter as a dimension on a graph with the values of a given parameter as a point along the axis. Three parameters would be a cube of possible configurations for the algorithm, and n-parameters would be an n-dimensional hypercube of possible configurations for the algorithm.The objective of algorithm tuning is to find the best point or points in that hypercube for your problem.\n",
    "    \n",
    "    We can approach this search problem by using automated methods that impose a grid on the possibility space and sample where good algorithm configuration might be. We can then use those points in an optimization algorithm to zoom in on the best performance.\n",
    "\n",
    "    We can repeat this process with a number of well performing methods and explore the best you can achieve with each. It is strongly advisable that the process is automated and reasonably coarse grained as we can quickly reach points of \"diminishing returns\" (fractional percentage performance increases) that may not translate to the production system.\n",
    "\n",
    "    Note: The more tuned the parameters of an algorithm, the more biased the algorithm will be to the training data and test harness. This strategy can be effective, but it can also lead to more fragile models that overfit your test harness and don’t perform as well in practice.\n",
    "    \n",
    "    When tuning algorithms, we must have a high confidence in the results given by your test harness. This means that we should be using techniques that reduce the variance of the performance measure you are using to assess algorithm runs. One suggestion is to perform \"repeated cross validation\" with a reasonably high number of folds (the exact number of which depends on your dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18ecc5",
   "metadata": {},
   "source": [
    "### 2. Ensembles\n",
    "    Ensemble methods are concerned with combining the results of multiple methods in order to get improved results. Ensemble methods work well when you have multiple “good enough” models that specialize in different parts of the problem.\n",
    "    Three ensemble strategies that we can explore are:\n",
    "        > Basic Ensemble Techniques\n",
    "            - Max Voting\n",
    "            - Averaging\n",
    "            - Weighted Average\n",
    "        > Advanced Ensemble Techniques\n",
    "            - Stacking\n",
    "            - Blending\n",
    "            - Bagging (Bootstrapping with replacement and voting)\n",
    "            - Boosting\n",
    "           > Algorithms based on Bagging and Boosting\n",
    "            - Bagging meta-estimator\n",
    "            - Random Forest\n",
    "            - AdaBoost\n",
    "            - GBM\n",
    "            - XGB\n",
    "            - Light GBM\n",
    "            - CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36142f5b",
   "metadata": {},
   "source": [
    "#### Max Voting: \n",
    "    The max voting method is generally used for classification problems. In this technique, multiple models are used to make predictions for each data point. The predictions by each model are considered as a ‘vote’. The predictions which we get from the majority of the models are used as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68a3e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End time: 1.0619604587554932\n",
      "Test Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, shuffle=True)\n",
    "clf_1 = LogisticRegression()\n",
    "clf_2 = SVC(random_state=0)\n",
    "start_time = time.time()\n",
    "clf = VotingClassifier(estimators=[('lr', clf_1),('svc', clf_2)], n_jobs=-1, voting='hard')\n",
    "clf.fit(x_train, y_train)\n",
    "print(f\"End time: {time.time()-start_time}\")\n",
    "print(\"Test Accuracy: {}\".format(clf.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7f720",
   "metadata": {},
   "source": [
    "#### Averaging\n",
    "    Similar to the max voting technique, multiple predictions are made for each data point in averaging. In this method, we take an average of predictions from all the models and use it to make the final prediction. Averaging can be used for making predictions in regression problems or while calculating probabilities for classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa14b7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0 1 2 2 1 2]\n",
      "Accuracy score 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, shuffle=True)\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "model2.fit(x_train, y_train)\n",
    "model3.fit(x_train, y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(x_test)\n",
    "#predict_proba gives probability of each target class for all the instances\n",
    "pred2 = model2.predict_proba(x_test)\n",
    "pred3 = model3.predict_proba(x_test)\n",
    "\n",
    "finalpreds = (pred1+pred2+pred3)/3\n",
    "#print(finalpreds) #this contains average probability of all the models for each class of all instances\n",
    "final_test_preds = np.argmax(finalpreds, axis=1)\n",
    "print(final_test_preds)\n",
    "print(f\"Accuracy score {accuracy_score(y_test, final_test_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ba4e5b",
   "metadata": {},
   "source": [
    "#### Weighted average:\n",
    "    This is an extension of the averaging method. All models are assigned different weights defining the importance of each model for prediction. For instance, if two of your colleagues are critics, while others have no prior experience in this field, then the answers by these two friends are given more importance as compared to the other people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3a2baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0 1 2 2 1 2]\n",
      "Accuracy score 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, shuffle=True)\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "model2.fit(x_train, y_train)\n",
    "model3.fit(x_train, y_train)\n",
    "\n",
    "pred1 = model1.predict_proba(x_test)\n",
    "#predict_proba gives probability of each target class for all the instances\n",
    "pred2 = model2.predict_proba(x_test)\n",
    "pred3 = model3.predict_proba(x_test)\n",
    "\n",
    "finalpreds = (pred1*0.3+pred2*0.3+pred3*0.4)\n",
    "#print(finalpreds) #this contains average probability of all the models for each class of all instances\n",
    "final_test_preds = np.argmax(finalpreds, axis=1)\n",
    "print(final_test_preds)\n",
    "print(f\"Accuracy score {accuracy_score(y_test, final_test_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d47ae",
   "metadata": {},
   "source": [
    "#### Stacking:\n",
    "    Stacking or stacked generalisation is a powerful and competitions winning ensembling technique.The architecture of a stacking model involves two or more base models, often referred to as level-0 models, and a meta-model that combines the predictions of the base models, referred to as a level-1 model. Stacking makes prediction by using a meta-model trained from a pool of base models.In simple terms, it uses predictions from multiple models (for example decision tree, knn or svm) to build a new model. This model is used for making predictions on the test set.\n",
    "    Working:\n",
    "        > To train a base model,Stacking uses K-fold cross validation technique.\n",
    "        > We have Train Data and Test Data. Assume we are using 4-fold cross validation to train base models, the train_data is then divided into 4 parts.\n",
    "        > Each base model like decision tree or svm is trained on 3 folds and predicted on fourth fold.Likewise all the folds(isntances) undergo this process and we get predictions for all the instances using the base class.\n",
    "        > The predictions of training data of first base class (lets say p1) is used as one feature for meta model\n",
    "        > Now the same process is done using another base model(like svm) for all the folds and the predictions(say p2) obtaines are used as another feature for meta model.\n",
    "        > Once the base model predictions are obtained for training data, the base model is again trained on the whole training set without cv.This trained base model is now tested on test set and we will get the predictions of test set.\n",
    "        > These test predictions ( say t1) is stored. Like wise another base model is also used to get test predictions (say t2)\n",
    "        > Once all the trainings and predictions of base models are done on training and test set, The meta model(say knn) is used to train the training set.\n",
    "        > But now the features will be the predictions done by base models on all training instances (p1, p2, .. ,pn)\n",
    "        > The metal model will be trained and model is built\n",
    "        > This model will be now used on test set. The test input will be the predictions of base model on test set(t1, t2, .., tn)\n",
    "        > The test predictions made by meta model on test set are the final predictions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4dcce48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X, Y = load_iris(as_frame=True, return_X_y=True)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=0, shuffle=True)\n",
    "\n",
    "def stacking(model, train, y_tr, test, nfolds=10):\n",
    "#     y_tr = y_tr.to_numpy().reshape(-1)\n",
    "    folds = StratifiedKFold(n_splits=nfolds, random_state=0, shuffle=True)\n",
    "    train_preds = np.empty((0, 1), float)\n",
    "#     test_preds = np.empty((test.shape[0], 1), float)\n",
    "    clf = model\n",
    "    for train_indices, val_indices in folds.split(train, y_tr.values):\n",
    "        x_training, x_val =  train.iloc[train_indices], train.iloc[val_indices]\n",
    "        y_training, y_val = y_tr.iloc[train_indices], y_tr.iloc[val_indices]\n",
    "        clf.fit(x_training, y_training)\n",
    "        train_preds = np.append(train_preds, clf.predict(x_val))\n",
    "    #retraining whole training set\n",
    "    clf.fit(train, y_tr)\n",
    "    #predicting test set using whole model and to generate test features\n",
    "    test_preds = clf.predict(test)\n",
    "    return test_preds.reshape(-1,1), train_preds\n",
    "    \n",
    "#Base models training and creating new features\n",
    "test_preds_1, train_preds_1 = stacking(DecisionTreeClassifier(), x_train, y_train, x_test)\n",
    "test_preds_2, train_preds_2 = stacking(SVC(), x_train, y_train, x_test)\n",
    "\n",
    "# convert into dataframe\n",
    "train_pred_1 = pd.DataFrame(train_preds_1, columns=['m1'])\n",
    "test_pred_1 = pd.DataFrame(test_preds_1, columns=['m1'])\n",
    "train_pred_2 = pd.DataFrame(train_preds_2, columns=['m2'])\n",
    "test_pred_2 = pd.DataFrame(test_preds_2, columns=['m2'])\n",
    "\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_train_features = pd.concat([train_pred_1, train_pred_2], axis=1)\n",
    "meta_test_features = pd.concat([test_pred_1, test_pred_2], axis=1)\n",
    "meta_model.fit(meta_train_features, y_train)\n",
    "meta_model.score(meta_test_features, y_test)\n",
    "\n",
    "#Observation:\n",
    "#There must be something wrong in the implementation.The fitting of meta model with features and its y_train must not be matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b39fe3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.964 (0.041)\n",
      ">knn 0.964 (0.037)\n",
      ">cart 0.947 (0.050)\n",
      ">svm 0.964 (0.045)\n",
      ">bayes 0.956 (0.047)\n",
      ">stacking 0.962 (0.041)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    #  X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "    return X, y\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('cart', DecisionTreeClassifier()))\n",
    "    level0.append(('svm', SVC()))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4aa005",
   "metadata": {},
   "source": [
    "#### Blending:\n",
    "    Blending follows the same approach as stacking but uses only a holdout (validation) set from the train set to make predictions. In other words, unlike stacking, the predictions are made on the holdout set only. The holdout set and the predictions on it are used as meta features to build a model which is run on the test set.\n",
    "    1. The train set is split into training and validation sets\n",
    "    2. Base models are fitted on training data, and predictions are made on holdout validation set and test_data.These predictions are used as meta features for both training set and test set i.e validation set base predictions as training meta features and test set predictions as test set meta features.\n",
    "    3. Now the meta model is trained on validation set original features and also the meta features.\n",
    "    4. The trained meta model is used for prediction on the test set(having its original features and the test meta features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d2eaad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3350, 20), Val: (1650, 20), Test: (5000, 20)\n",
      "Blending Accuracy: 97.800\n"
     ]
    }
   ],
   "source": [
    "# blending ensemble for classification using hard voting\n",
    "from numpy import hstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr', LogisticRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeClassifier()))\n",
    "    models.append(('svm', SVC()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "    # fit all models on the training set and predict on hold out set\n",
    "    meta_X = list()\n",
    "    for name, model in models:\n",
    "        # fit in training set\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict on hold out set\n",
    "        yhat = model.predict(X_val)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store predictions as input for blending\n",
    "        meta_X.append(yhat)\n",
    "    #     meta_X.append(X_val) #adding the actual features is failing the blending logistic regression model to converge\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # define blending model\n",
    "    blender = LogisticRegression()\n",
    "    # fit on predictions from base models\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    " # make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "    # make predictions with base models\n",
    "    meta_X = list()\n",
    "    for name, model in models:\n",
    "        # predict with base model\n",
    "        yhat = model.predict(X_test)\n",
    "        # reshape predictions into a matrix with one column\n",
    "        yhat = yhat.reshape(len(yhat), 1)\n",
    "        # store prediction\n",
    "        meta_X.append(yhat)\n",
    "#     meta_X.append(X_test)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s, Test: %s' % (X_train.shape, X_val.shape, X_test.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make predictions on test set\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "# evaluate predictions\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Blending Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cd1b264b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3350, 20), Val: (1650, 20), Test: (5000, 20)\n",
      "Blending Accuracy: 98.260\n"
     ]
    }
   ],
   "source": [
    "from numpy import hstack\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr', LogisticRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeClassifier()))\n",
    "    models.append(('svm', SVC(probability=True)))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "# fit the blending ensemble\n",
    "def fit_ensemble(models, X_train, X_val, y_train, y_val):\n",
    "    # fit all models on the training set and predict on hold out set\n",
    "    meta_X = list()\n",
    "    for name, model in models:\n",
    "        # fit in training set\n",
    "        model.fit(X_train, y_train)\n",
    "        # predict on hold out set\n",
    "        yhat = model.predict_proba(X_val)\n",
    "        # store predictions as input for blending\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # define blending model\n",
    "    blender = LogisticRegression()\n",
    "    # fit on predictions from base models\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# make a prediction with the blending ensemble\n",
    "def predict_ensemble(models, blender, X_test):\n",
    "    # make predictions with base models\n",
    "    meta_X = list()\n",
    "    for name, model in models:\n",
    "        # predict with base model\n",
    "        yhat = model.predict_proba(X_test)\n",
    "        # store prediction\n",
    "        meta_X.append(yhat)\n",
    "    # create 2d array from predictions, each set is an input feature\n",
    "    meta_X = hstack(meta_X)\n",
    "    # predict\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# split dataset into train and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.5, random_state=1)\n",
    "# split training set into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.33, random_state=1)\n",
    "# summarize data split\n",
    "print('Train: %s, Val: %s, Test: %s' % (X_train.shape, X_val.shape, X_test.shape))\n",
    "# create the base models\n",
    "models = get_models()\n",
    "# train the blending ensemble\n",
    "blender = fit_ensemble(models, X_train, X_val, y_train, y_val)\n",
    "# make predictions on test set\n",
    "yhat = predict_ensemble(models, blender, X_test)\n",
    "# evaluate predictions\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Blending Accuracy: %.3f' % (score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2905b7",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "    In this case, we can see that blending the class probabilities resulted in a lift in classification accuracy to about 98.240 percent.A blending ensemble is only effective if it is able to out-perform any single contributing model.We can confirm this by evaluating each of the base models in isolation. Each base model can be fit on the entire training dataset (unlike the blending ensemble) and evaluated on the test dataset (just like the blending ensemble)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef12a8e",
   "metadata": {},
   "source": [
    "#### Bagging:\n",
    "    The idea behind bagging is combining the results of multiple models (for instance, all decision trees) to get a generalized result. Here’s a question: If you create all the models on the same set of data and combine it, will it be useful? There is a high chance that these models will give the same result since they are getting the same input. So how can we solve this problem? One of the techniques is bootstrapping.\n",
    "\n",
    "    Bootstrapping is a sampling technique in which we create subsets of observations from the original dataset, with replacement. The size of the subsets is the same as the size of the original set.\n",
    "\n",
    "    Bagging (or Bootstrap Aggregating) technique uses these subsets (bags) to get a fair idea of the distribution (complete set). The size of subsets created for bagging may be less than the original set.\n",
    "    \n",
    "    1. Multiple subsets are created from the original dataset, selecting observations with replacement.\n",
    "    2. A base model (weak model) is created on each of these subsets.\n",
    "    3. The models run in parallel and are independent of each other.\n",
    "    4. The final predictions are determined by combining the predictions from all the models.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1c168",
   "metadata": {},
   "source": [
    "#### Boosting\n",
    "    Before we go further, here’s another question for you: If a data point is incorrectly predicted by the first model, and then the next (probably all models), will combining the predictions provide better results? Such situations are taken care of by boosting.\n",
    "\n",
    "    Boosting is a sequential process, where each subsequent model attempts to correct the errors of the previous model. The succeeding models are dependent on the previous model. Let’s understand the way boosting works in the below steps.\n",
    "\n",
    "    1. A subset is created from the original dataset.\n",
    "    2. Initially, all data points are given equal weights.\n",
    "    3. A base model is created on this subset.\n",
    "    4. This model is used to make predictions on the whole dataset.\n",
    "    5. Errors are calculated using the actual values and predicted values.\n",
    "    6. The observations which are incorrectly predicted, are given higher weights.Weights can be determined using the error value. For instance, higher the error more is the weight assigned to the observation.\n",
    "    7. Another model is created and predictions are made on the dataset.\n",
    "        (This model tries to correct the errors from the previous model)\n",
    "    8. Similarly, multiple models are created, each correcting the errors of the previous model.\n",
    "    9. This process is repeated until the error function does not change, or the maximum limit of the number of estimators is reached.\n",
    "    10. The final model (strong learner) is the weighted mean of all the models (weak learners)\n",
    "    \n",
    "    Thus, the boosting algorithm combines a number of weak learners to form a strong learner. The individual models would not perform well on the entire dataset, but they work well for some part of the dataset. Thus, each model actually boosts the performance of the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83b296",
   "metadata": {},
   "source": [
    "### 3. Extreme Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761a2c7d",
   "metadata": {},
   "source": [
    "    The previous two strategies have looked at getting more from machine learning algorithms. This strategy is about exposing more structure in the problem for the algorithms to learn. In data preparation learned about feature decomposition and aggregation in order to better normalize the data for machine learning algorithms. In this strategy, we push that idea to the limits.\n",
    "\n",
    "    Think of your data as having complex multi-dimensional structures embedded in it that machine learning algorithms know how to find and exploit to make decisions. You want to best expose those structures to algorithms so that the algorithms can do their best work. A difficulty is that some of those structures may be too dense or too complex for the algorithms to find without help. You may also have some knowledge of such structures from your domain expertise.\n",
    "    \n",
    "    Take attributes and decompose them widely into multiple features. Technically, what you are doing with this strategy is reducing dependencies and non-linear relationships into simpler independent linear relationships.\n",
    "    \n",
    "    Examples:\n",
    "        \n",
    "        Categorical: You have a categorical attribute that had the values [red, green blue], you could split that into 3 binary attributes of red, green and blue and give each instance a 1 or 0 value for each.\n",
    "        \n",
    "        Real: You have a real valued quantity that has values ranging from 0 to 1000. You could create 10 binary attributes, each representing a bin of values (0-99 for bin 1, 100-199 for bin 2, etc.) and assign each instance a binary value (1/0) for the bins.\n",
    "\n",
    "    Note: It is recommended to perform this process one step at a time and creating a new test/train dataset for each modification you make and then test algorithms on the dataset. This will start to give you an intuition for attributes and features in the database that are exposing more or less information to the algorithms and the effects on the performance measure. You can use these results to guide further extreme decompositions or aggregations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05afb85d",
   "metadata": {},
   "source": [
    "### Cheatsheet to improve results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb53c47",
   "metadata": {},
   "source": [
    "    Choose one technique and one method from it and apply and check the results and improvise and add another and so on\n",
    "    1.Improve Performance With Data.\n",
    "    2.Improve Performance With Algorithms.\n",
    "    3.Improve Performance With Algorithm Tuning.\n",
    "    4.Improve Performance With Ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415cae0",
   "metadata": {},
   "source": [
    "#### 1.Improve Performance With Data.\n",
    "    > Data Tactics\n",
    "        Get More Data. Can you get more or better quality data? Modern nonlinear machine learning techniques like deep learning continue to improve in performance with more data.\n",
    "    \n",
    "    > Invent More Data.\n",
    "        If you can’t get more data, can you generate new data? Perhaps you can augment or permute existing data or use a probabilistic model to generate new data.\n",
    "\n",
    "    > Clean Your Data.\n",
    "        Can you improve the signal in your data? Perhaps there are missing or corrupt observations that can be fixed or removed, or outlier values outside of reasonable ranges that can be fixed or removed in order to lift the quality of your data.\n",
    "\n",
    "    > Resample Data.\n",
    "        Can you resample data to change the size or distribution? Perhaps you can use a much smaller sample of data for your experiments to speed things up or over-sample or under-sample observations of a specific type to better represent them in your dataset.\n",
    "\n",
    "    > Reframe Your Problem: \n",
    "    Can you change the type of prediction problem you are solving? Reframe your data as a regression, binary or multiclass classification, time series, anomaly detection, rating, recommender, etc. type problem.\n",
    "\n",
    "    > Rescale Your Data.\n",
    "        Can you rescale numeric input variables? Normalization and standardization of input data can result in a lift in performance on algorithms that use weighted inputs or distance measures.\n",
    "\n",
    "    > Transform Your Data.\n",
    "        Can you reshape your data distribution? Making input data more Gaussian or passing it through an exponential function may better expose features in the data to a learning algorithm.\n",
    "\n",
    "    > Project Your Data\n",
    "        Can you project your data into a lower dimensional space? You can use an unsupervised clustering or projection method to create an entirely new compressed representation of your dataset.\n",
    "\n",
    "    > Feature Selection\n",
    "        Are all input variables equally important? Use feature selection and feature importance methods to create new views of your data to explore with modeling algorithms.\n",
    "\n",
    "    > Feature Engineering\n",
    "        Can you create and add new data features? Perhaps there are attributes that can be decomposed into multiple new values (like categories, dates or strings) or attributes that can be aggregated to signify an event (like a count, binary flag or statistical summary)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d612effd",
   "metadata": {},
   "source": [
    "#### 2.Improve Performance With Algorithms.\n",
    "\n",
    "    > Resampling Method. \n",
    "        What resampling method is used to estimate skill on new data? Use a method and configuration that makes the best use of available data. The k-fold cross-validation method with a hold out validation dataset might be a best practice.\n",
    "\n",
    "    > Evaluation Metric.\n",
    "        What metric is used to evaluate the skill of predictions? Use a metric that best captures the requirements of the problem and the domain. It probably isn’t classification accuracy.\n",
    "\n",
    "    > Baseline Performance.\n",
    "        What is the baseline performance for comparing algorithms? Use a random algorithm or a zero rule algorithm (predict mean or mode) to establish a baseline by which to rank all evaluated algorithms.\n",
    "\n",
    "    > Spot Check Linear Algorithms.\n",
    "        What linear algorithms work well? Linear methods are often more biased, are easy to understand and are fast to train. They are preferred if you can achieve good results. Evaluate a diverse suite of linear methods.\n",
    "\n",
    "    > Spot Check Nonlinear Algorithms.\n",
    "        What nonlinear algorithms work well? Nonlinear algorithms often require more data, have greater complexity but can achieve better performance. Evaluate a diverse suite of nonlinear methods.\n",
    "\n",
    "    > Steal from Literature.\n",
    "        What algorithms are reported in the literature to work well on your problem? Perhaps you can get ideas of algorithm types or extensions of classical methods to explore on your problem.\n",
    "\n",
    "    > Standard Configurations.\n",
    "        What are the standard configurations for the algorithms being evaluated? Each algorithm needs an opportunity to do well on your problem. This does not mean tune the parameters (yet) but it does mean to investigate how to configure each algorithm well and give it a fighting chance in the algorithm bake-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f2f4d",
   "metadata": {},
   "source": [
    "#### 3.Improve Performance With Algorithm Tuning.\n",
    "    \n",
    "    > Diagnostics.\n",
    "        What diagnostics and you review about your algorithm? Perhaps you can review learning curves to understand whether the method is over or underfitting the problem, and then correct. Different algorithms may offer different visualizations and diagnostics. Review what the algorithm is predicting right and wrong.\n",
    "\n",
    "    > Try Intuition.\n",
    "        What does your gut tell you? If you fiddle with parameters for long enough and the feedback cycle is short, you can develop an intuition for how to configure an algorithm on a problem. Try this out and see if you can come up with new parameter configurations to try on your larger test harness.\n",
    "\n",
    "    > Steal from Literature.\n",
    "        What parameters or parameter ranges are used in the literature? Evaluating the performance of standard parameters is a great place to start any tuning activity.\n",
    "\n",
    "    > Random Search.\n",
    "        What parameters can use random search? Perhaps you can use random search of algorithm hyperparameters to expose configurations that you would never think to try.\n",
    "\n",
    "    > Grid Search.\n",
    "        What parameters can use grid search? Perhaps there are grids of standard hyperparameter values that you can enumerate to find good configurations, then repeat the process with finer and finer grids.\n",
    "\n",
    "    > Optimize. \n",
    "        What parameters can you optimize? Perhaps there are parameters like structure or learning rate than can be tuned using a direct search procedure (like pattern search) or stochastic optimization (like a genetic algorithm).\n",
    "\n",
    "    > Alternate Implementations.\n",
    "        What other implementations of the algorithm are available? Perhaps an alternate implementation of the method can achieve better results on the same data. Each algorithm has a myriad of micro-decisions that must be made by the algorithm implementor. Some of these decisions may affect skill on your problem.\n",
    "\n",
    "    > Algorithm Extensions.\n",
    "        What are common extensions to the algorithm? Perhaps you can lift performance by evaluating common or standard extensions to the method. This may require implementation work.\n",
    "\n",
    "    > Algorithm Customizations.\n",
    "        What customizations can be made to the algorithm for your specific case? Perhaps there are modifications that you can make to the algorithm for your data, from loss function, internal optimization methods to algorithm specific decisions.\n",
    "\n",
    "    > Contact Experts.\n",
    "        What do algorithm experts recommend in your case? Write a short email summarizing your prediction problem and what you have tried to one or more expert academics on the algorithm. This may reveal leading edge work or academic work previously unknown to you with new or fresh ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9594b8ea",
   "metadata": {},
   "source": [
    "#### 4.Improve Performance With Ensembles.\n",
    "    \n",
    "    > Blend Model Predictions.\n",
    "        Can you combine the predictions from multiple models directly? Perhaps you could use the same or different algorithms to make multiple models. Take the mean or mode from the predictions of multiple well-performing models.\n",
    "\n",
    "    > Blend Data Representations.\n",
    "        Can you combine predictions from models trained on different data representations? You may have many different projections of your problem which can be used to train well-performing algorithms, whose predictions can then be combined.\n",
    "\n",
    "    > Blend Data Samples.\n",
    "        Can you combine models trained on different views of your data? Perhaps you can create multiple subsamples of your training data and train a well-performing algorithm, then combine predictions. This is called bootstrap aggregation or bagging and works best when the predictions from each model are skillful but in different ways (uncorrelated).\n",
    "\n",
    "    > Correct Predictions.\n",
    "        Can you correct the predictions of well-performing models? Perhaps you can explicitly correct predictions or use a method like boosting to learn how to correct prediction errors.\n",
    "        \n",
    "    > Learn to Combine.\n",
    "        Can you use a new model to learn how to best combine the predictions from multiple well-performing models? This is called stacked generalization or stacking and often works well when the submodels are skillful but in different ways and the aggregator model is a simple linear weighting of the predictions. This process can be repeated multiple layers deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df93b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
