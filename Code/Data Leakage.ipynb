{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdcafc0e",
   "metadata": {},
   "source": [
    "#### Data leakage:\n",
    "    Data Leakage in machine learning happens when the data that we are used to training a machine learning algorithm is having the information about the target which the model is trying to predict, this results in unreliable and bad prediction outcomes after model deployment but unrealistically best training and possibly even the best validation accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc2292",
   "metadata": {},
   "source": [
    "    ------------------------------------------------------------------------------------------------------------------------\n",
    "    Data Leakage is the scenario where the Machine Learning Model is already aware of some part of test data after training.Data Leakage refers to a mistake that is made by the creator of a machine learning model in which they accidentally share the information between the test and training data sets.\n",
    "     \n",
    "     The purpose of holding the test set during training is to estimate the performance of the model when given totally unseen data which inturn gives us an idea of how well the model is generalised to unseen isntances.But, Data Leakage process spoils this purpose and exposes the test set to the model during training itself when care is not taken.\n",
    "     \n",
    "     When such a model is then used on truly unseen data that is coming mostly on the production side, then the performance of that model will be much lower than expected after deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f5a873",
   "metadata": {},
   "source": [
    "    ------------------------------------------------------------------------------------------------------------------------\n",
    "    There are two main types of leakage: \n",
    "        - target leakage\n",
    "        - train-test contamination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d7f83",
   "metadata": {},
   "source": [
    "#### Target Leakage:\n",
    "     Target leakage occurs when your predictors include data that will not be available at the time you make predictions. It is important to think about target leakage in terms of the timing or chronological order that data becomes available, not merely whether a feature helps make good predictions.\n",
    "       \n",
    "       Eg :  Imagine you want to predict who will get sick with pneumonia. Below is the raw data\n",
    "       \n",
    "           --------------------------------------------------------------------\n",
    "           got_pneumonia  | age |\tweight|  male\t | took_antibiotic_medicine\n",
    "           --------------------------------------------------------------------\n",
    "               False\t  |   65|\t 100  |    False  |\t  False\t\n",
    "               False\t  |   72|\t 130  |     True  |      False\n",
    "               True\t   |   58|\t 100  |\tFalse  |\t  True\n",
    "           ---------------------------------------------------------------------    \n",
    "\n",
    "    People 'take antibiotic medicines' after getting pneumonia in order to recover. The raw data shows a strong relationship between those columns, but took_antibiotic_medicine is frequently changed after the value for got_pneumonia is determined. This is target leakage.\n",
    "    \n",
    "    The model would see that anyone who has a value of False for took_antibiotic_medicine didn't have pneumonia. Since validation data comes from the same source as training data, the pattern will repeat itself in validation, and the model will have great validation (or cross-validation) scores.But the model will be very inaccurate when subsequently deployed in the real world, because even patients who will get pneumonia won't have received antibiotics yet when we need to make predictions about their future health.\n",
    "    \n",
    "    Possible Solution : To prevent this type of data leakage, any variable updated (or created) after the target value is realized should be excluded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e527739",
   "metadata": {},
   "source": [
    "#### Train-Test Contamination:\n",
    "    A different type of leak occurs when you aren't careful to distinguish training data from validation data.If we recall, validation is meant to be a measure of how the model does on data that it hasn't considered before. One can corrupt this process in subtle ways if the validation data affects the preprocessing behavior.\n",
    "    \n",
    "    While solving a Machine learning problem statement, firstly we do the data cleaning and preprocessing which involves the following steps:\n",
    "    - Evaluating the parameters(mean, sd, variance) for normalizing or rescaling features\n",
    "    - Finding the minimum and maximum values of a particular feature\n",
    "    - Normalize the particular feature in our dataset\n",
    "    - Removing the outliers\n",
    "    - Fill or completely remove the missing data in our dataset\n",
    "    - Encodings\n",
    "    - Feature engineering like feature extraction, feature selection\n",
    "    \n",
    "    Possible solution: All the preprocessing steps should be done using only the training set and mostly in cross validation inner loop with the help of scikit Pipeline or R caret package.By doing so, the transformation will not be applied to hold out validation set during training. The model wont be aware of anything about the hold out set and this results in realistic estimations of unseen data.\n",
    "    \n",
    "    Applying preprocessing techniques to the entire dataset will cause the model to learn not only the training set but also the test set and hence the data leakage.If you perform techniques like feature selection on all of the data and then cross-validate, then the test data in each fold of the cross-validation procedure was also used to choose the features and this is what biases the performance analysis.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7b9801",
   "metadata": {},
   "source": [
    "#### Examples:\n",
    "    1.Imagine, we are working on a problem statement in which we have to build a model that predicts a certain medical condition. If we have a feature that indicates whether a patient had a surgery related to that medical condition, then it causes data leakage and we should never be included that as a feature in the training data. The indication of surgery is highly predictive of the medical condition and would probably not be available in all cases. If we already know that a patient had a surgery related to a medical condition, then we may not even require a predictive model to start with.\n",
    "    \n",
    "    2. Letâ€™s imagine we are working on a problem statement in which we have to build a model that predicts if a user will stay on a website. Including features that expose the information about future visits will cause the problem of data leakage. So, we have to use only features about the current session because information about the future sessions is not generally available after we deployed our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae08efd",
   "metadata": {},
   "source": [
    "#### How to detect Data Leakage?\n",
    "    1. In general, if we see that the model which we build is too good to be true (i.,e gives predicted and actual output the same), then we should get suspicious and data leakage cannot be ruled out. At that time, the model might be somehow memorizing the relations between feature and target instead of learning and generalizing it for the unseen data. So, it is advised that before the testing, the prior documented results are weighed against the expected results.\n",
    "    \n",
    "    2.While doing the Exploratory Data Analysis (EDA), we may detect features that are very highly correlated with the target variable. Of course, some features are more correlated than others but a surprisingly high correlation needs to be checked and handled carefully. We should pay close attention to those features.\n",
    "    \n",
    "    3.After the completion of the model training, if features are having very high weights(check using feature_importances_), then we should pay close attention. Those features might be leaky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8996f65f",
   "metadata": {},
   "source": [
    "#### Tips to combat Data Leakage:\n",
    "    1. Temporal Cutoff\n",
    "        - Remove all data just prior to the event of interest, focusing on the time you learned about a fact or observation rather than the time the observation occurred.When dealing with time-series data, we should pay more attention to data leakage. For example, if we somehow use data from the future when doing computations for current features or predictions, it is highly likely to end up with a leaked model. It generally happens when the data is randomly split into train and test subsets. So, when working with time-series data, we put a cutoff value on time which might be very useful, as it prevents us from getting any information after the time of prediction.\n",
    "        \n",
    "      2. Add Noise\n",
    "          - Add random noise to input data to try and smooth out the effects of possibly leaking variables.\n",
    "\n",
    "    3. Remove Leaky Variables\n",
    "        - Evaluate simple rule based models line OneR using variables like account numbers and IDs and the like to see if these variables are leaky, and if so, remove them. If you suspect a variable is leaky, consider removing it.Extract always the appropriate set of features.\n",
    "     \n",
    "    4. Use Pipelines\n",
    "        - Heavily use pipeline architectures that allow a sequence of data preparation steps to be performed within cross validation folds, such as the caret package in R and Pipelines in scikit-learn.\n",
    "     \n",
    "     5.Use a Holdout Dataset\n",
    "         - Hold back an unseen validation dataset as a final sanity check of your model before you use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1037b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d895afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card  reports       age  income     share  expenditure  owner  selfemp  \\\n",
       "0  True        0  37.66667  4.5200  0.033270   124.983300   True    False   \n",
       "1  True        0  33.25000  2.4200  0.005217     9.854167  False    False   \n",
       "2  True        0  33.66667  4.5000  0.004156    15.000000   True    False   \n",
       "3  True        0  30.50000  2.5400  0.065214   137.869200  False    False   \n",
       "4  True        0  32.16667  9.7867  0.067051   546.503300   True    False   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example to show Target Leakage using credit card eligibility data set\n",
    "\n",
    "data = pd.read_csv(\"E:\\Learning\\ML\\Datasets\\data\\AER_credit_card_data\\AER_credit_card_data.csv\", true_values=['yes'], false_values=['no'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79852958",
   "metadata": {},
   "source": [
    "#### Info:\n",
    "    Here is a summary of the data\n",
    "        card: 1 if credit card application accepted, 0 if not\n",
    "        reports: Number of major derogatory reports\n",
    "        age: Age in years plus twelfths of a year\n",
    "        income: Yearly income (divided by 10,000)\n",
    "        share: Ratio of monthly credit card expenditure to yearly income\n",
    "        expenditure: Average monthly credit card expenditure\n",
    "        owner: 1 if owns home, 0 if rents\n",
    "        selfempl: 1 if self-employed, 0 if not\n",
    "        dependents: 1 + number of dependents\n",
    "        months: Months living at current address\n",
    "        majorcards: Number of major credit cards held\n",
    "        active: Number of active credit accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0d0afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, data.columns != 'card']\n",
    "Y = data['card']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abb55dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1319, 11)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31088ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1319,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0ba71bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1023\n",
       "False     296\n",
       "Name: card, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "45d93574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "1314     True\n",
       "1315    False\n",
       "1316     True\n",
       "1317     True\n",
       "1318     True\n",
       "Name: card, Length: 1319, dtype: bool"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f1ce818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall average Cross validtion score of the model is: 0.9802972472819803\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "pipe = make_pipeline(clf)\n",
    "cv = KFold(n_splits=10, random_state=0, shuffle=True)\n",
    "scores = cross_val_score(pipe, X, Y, cv=cv, scoring='accuracy', error_score='raise')\n",
    "print(f\"Overall average Cross validtion score of the model is: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb8a70",
   "metadata": {},
   "source": [
    "#### Observation: \n",
    "    It's very rare to find models that are accurate 98% of the time. It happens, but it's uncommon enough that we should inspect the data more closely for target leakage. A few variables look suspicious. For example, does expenditure mean expenditure on this card or on cards used before applying? At this point, basic data comparisons can be very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5200b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_cardholders = X.expenditure[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c66963c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       124.983300\n",
       "1         9.854167\n",
       "2        15.000000\n",
       "3       137.869200\n",
       "4       546.503300\n",
       "           ...    \n",
       "1310      4.583333\n",
       "1314      7.333333\n",
       "1316    101.298300\n",
       "1317     26.996670\n",
       "1318    344.157500\n",
       "Name: expenditure, Length: 1023, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenditure_cardholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b81e1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(expenditure_cardholders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9dcb71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditure_noncardholders = X.expenditure[~Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2abd0d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Counter(expenditure_noncardholders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "891c629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of those who did not receive a card and had no expenditures: 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of those who did not receive a card and had no expenditures: %.2f\"%((expenditure_noncardholders==0).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8ccb907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of those who received a card and had no expenditures: 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of those who received a card and had no expenditures: %.2f\"%((expenditure_cardholders==0).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcead9f1",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "    If we observe, everyone who did not receive a card had no expenditures, while only 2% of people had no expenditures after receiving a card meaning 98 percent people had expenditure after receiving the card. It's not surprising that our model appeared to have a high accuracy. But this also seems to be a case of target leakage, where expenditures probably means expenditures on the card they applied for.\n",
    "    Since share is partially determined by expenditure, it should be excluded too. The variables active and majorcards are a little less clear, but from the description, they sound concerning. In most situations, it's better to be safe than sorry if you can't track down the people who created the data to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0583fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reports       age  income  owner  selfemp  dependents  months\n",
       "0        0  37.66667  4.5200   True    False           3      54\n",
       "1        0  33.25000  2.4200  False    False           3      34\n",
       "2        0  33.66667  4.5000   True    False           4      58\n",
       "3        0  30.50000  2.5400  False    False           0      25\n",
       "4        0  32.16667  9.7867   True    False           2      64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping leaky predictors from dataset\n",
    "potential_leakage = ['expenditure', 'share', 'active', 'majorcards']\n",
    "X = X.drop(potential_leakage, axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bebf7b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall average Cross validtion score of the model is: 0.8256187832523711\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(pipe, X, Y, cv=cv, scoring='accuracy', error_score='raise')\n",
    "print(f\"Overall average Cross validtion score of the model is: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1659d5b7",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "    This accuracy is quite a bit lower, which might be disappointing. However, we can expect it to be right about 80% of the time when used on new applications, whereas the leaky model would likely do much worse than that (in spite of its higher apparent score in cross-validation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
